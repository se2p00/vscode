{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def getPageHtml(url):\n",
    "    # Chrome WebDriver 옵션 설정\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # 브라우저 창이 표시되지 않도록 설정\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    #options.add_argument(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Chrome WebDriver 실행\n",
    "    driver = webdriver.Chrome('chromedriver', options=options)\n",
    "\n",
    "    # 페이지 열기\n",
    "    driver.get(url)\n",
    "\n",
    "    # 페이지의 초기 높이 가져오기\n",
    "    scroll_pause_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    # 페이지 충분히 스크롤\n",
    "    scroll_pause_time = 0.5  # 스크롤링 사이의 일시 정지 시간 (초)\n",
    "    while True:\n",
    "        # 스크롤을 아래로 이동\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # 일시 정지\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # 새로운 스크롤 높이 가져오기\n",
    "        new_scroll_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        # 더 이상 스크롤링이 되지 않으면 종료\n",
    "        if new_scroll_height == scroll_pause_height:\n",
    "            break\n",
    "\n",
    "        # 스크롤 높이 업데이트\n",
    "        scroll_pause_height = new_scroll_height\n",
    "\n",
    "    # 페이지의 HTML 가져오기\n",
    "    html = driver.page_source\n",
    "\n",
    "    # BeautifulSoup을 사용하여 HTML 파싱\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # WebDriver 종료\n",
    "    driver.quit()\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "\n",
    "def getUrl(dfrow):\n",
    "    \n",
    "    row = dfrow.copy()\n",
    "    # Chrome WebDriver 옵션 설정\n",
    "    options = webdriver.ChromeOptions()\n",
    "    if row['mall'] != '쿠팡':\n",
    "        options.add_argument(\"--headless\")  # 브라우저 창이 표시되지 않도록 설정\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")    \n",
    "    \n",
    "    url = row['링크']\n",
    "\n",
    "    driver = webdriver.Chrome('chromedriver', options=options)\n",
    "    driver.get(url)\n",
    "    #리디렉션 완료될 때까지 기다리기\n",
    "    while 'https://cr.shopping.naver.com/'in driver.current_url:\n",
    "        time.sleep(0)\n",
    "    time.sleep(.1)\n",
    "    html = driver.page_source\n",
    "    source = BeautifulSoup(html, \"html.parser\")\n",
    "    nlink = driver.current_url\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return (source, nlink)\n",
    "\n",
    "\n",
    "def get_prod_list_df(alist):\n",
    "    rowdata = []\n",
    "    for i in alist:\n",
    "        if i.select_one('span[class*=\"price_delivery\"]'):\n",
    "            title = i.select_one('div[class*=\"title\"] > a[href]')\n",
    "            link = title['href']\n",
    "            title = title.text\n",
    "            mall = i.select_one('div[class*=\"mall_title\"] > a[class*=\"mall\"]')\n",
    "            shopname = mall.text\n",
    "            if not shopname:\n",
    "                mallname = mall.select_one('img[alt]')['alt']\n",
    "            \n",
    "            price = i.select_one('span[class*=\"price_price\"]').text    \n",
    "            price = int(re.sub(r'[^0-9]', '', price))\n",
    "            delivery = i.select_one('span[class*=\"price_delivery\"]').text    \n",
    "            delivery = re.sub(r'[^0-9]', '', delivery)\n",
    "            if delivery=='':\n",
    "                delivery = 0;\n",
    "            else:\n",
    "                delivery = int(delivery)\n",
    "\n",
    "            sum = int(price)+int(delivery)\n",
    "            row = {'mall':mallname, 'shop':shopname, '제목':title, '가격':price, '배송비':delivery, '합계':sum, '링크':link}\n",
    "            rowdata.append(row)\n",
    "    df = pd.DataFrame(rowdata)\n",
    "    df['수량'] = df['제목'].str.extract(r'([0-9]+)개')\n",
    "    df = df.fillna(1)\n",
    "    df['수량']=df['수량'].astype(int)\n",
    "    df['단가'] = df['가격']/df['수량']\n",
    "    df['위반'] = df['단가']<31000\n",
    "    df = df[df['위반']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "#\n",
    "def get_mall_name(df):\n",
    "\n",
    "    selector = {'쿠팡':'div[class=\"prod-sale-vendor\"] a', 'G마켓':'span[class*=\"seller\"]', '11번가':'h1[class*=\"store_title\"]', '옥션':'span[class*=\"text__seller\"]'}\n",
    "    length = str(len(df))\n",
    "    print(length+'개의 목록 작업 시작')\n",
    "    \n",
    "    rlist = []\n",
    "    for i in range(len(df)):\n",
    "        print(str(i+1)+' 번째')\n",
    "        row = df.iloc[i].copy()\n",
    "        if row['mall'] in ['쿠팡', 'G마켓', '11번가', '옥션']:\n",
    "            print(row['mall'])\n",
    "            (soup, nlink) = getUrl(row)\n",
    "            shopInfo = soup.select_one(selector[row['mall']])\n",
    "            if shopInfo:\n",
    "                shop = shopInfo.text.strip()\n",
    "            else:\n",
    "                shop = ''\n",
    "            row['링크'] = nlink\n",
    "            row['platform'] = row['mall']\n",
    "            row['mall'] = shop\n",
    "        rlist.append(row)\n",
    "    ndf = pd.DataFrame(rlist)\n",
    "\n",
    "    return ndf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlList = [\"https://search.shopping.naver.com/search/all?frm=NVSHATC&origQuery=D10XPA&pagingIndex=1&pagingSize=80&productSet=total&query=D10XPA&sort=price_asc&timestamp=&viewType=list\",\n",
    "           \"https://search.shopping.naver.com/search/all?frm=NVSHATC&origQuery=D10XPA&pagingIndex=2&pagingSize=80&productSet=total&query=D10XPA&sort=price_asc&timestamp=&viewType=list\"\n",
    "           ]\n",
    "           \n",
    "alist = []\n",
    "for url in urlList:\n",
    "    soup = getPageHtml(url)\n",
    "    tag = soup.select_one('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx')\n",
    "    alist += tag.select('div[class*=\"product_item__\"]')\n",
    "\n",
    "\n",
    "df = get_prod_list_df(alist)\n",
    "df2 = get_mall_name(df)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('list.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
